{
  
    
        "post0": {
            "title": "",
            "content": "from pathlib import Path from tensorflow.keras.layers import Flatten, Dense, GlobalAveragePooling2D from tensorflow.keras.models import Model from keras_preprocessing.image import ImageDataGenerator from keras_applications.efficientnet import EfficientNetB0 import tensorflow as tf import tensorflow.keras.backend as K K.set_image_data_format(&#39;channels_last&#39;) import matplotlib.pyplot as plt %matplotlib inline . 2) Download dataset, and set directory paths . Image dataset comes from https://github.com/fastai/imagenette | The 320 px dataset is used here | Download link: https://s3.amazonaws.com/fast-ai-imageclas/imagenette2-320.tgz | . current_dir = Path().absolute() train_dir = current_dir/&#39;data/imagenette2-320/train&#39; val_dir = current_dir/&#39;data/imagenette2-320/val&#39; . 3) Create image data generators . If GPU runs out of memory, consider changing batch_size (e.g. batch_size = 16) | . batch_size=32 num_classes=10 input_shape = (224, 224, 3) # Normalize images train_datagen = ImageDataGenerator(rescale = 1./255) val_datagen = ImageDataGenerator(rescale = 1./255) train_it = train_datagen.flow_from_directory(train_dir, target_size=input_shape[:2], shuffle=True, class_mode=&#39;categorical&#39;, batch_size=batch_size) val_it = val_datagen.flow_from_directory(val_dir, target_size=input_shape[:2], shuffle=True, class_mode=&#39;categorical&#39;, batch_size=batch_size) . Found 9469 images belonging to 10 classes. Found 3925 images belonging to 10 classes. . 4) Create base model from EfficientNetB0 . We will fine tune EfficientNet to our dataset -&gt; include_top = False | . kwargs = {&#39;backend&#39;: tf.keras.backend, &#39;layers&#39;: tf.keras.layers, &#39;models&#39;: tf.keras.models, &#39;utils&#39;: tf.keras.utils} base_model = EfficientNetB0(include_top=False, weights=&#39;imagenet&#39;, input_shape=input_shape, **kwargs) . 5) Add some top layers, make base model untrainable, compile . x = base_model.output x = GlobalAveragePooling2D()(x) x = Flatten()(x) predictions = Dense(num_classes, activation=&#39;softmax&#39;)(x) new_model = Model(inputs=base_model.input, outputs=predictions) for layer in base_model.layers: layer.trainable = False new_model.compile(optimizer=&#39;Adam&#39;, loss = &#39;categorical_crossentropy&#39;, metrics=[&#39;accuracy&#39;]) new_model.summary() . Model: &#34;model&#34; __________________________________________________________________________________________________ Layer (type) Output Shape Param # Connected to ================================================================================================== input_1 (InputLayer) [(None, 224, 224, 3) 0 __________________________________________________________________________________________________ stem_conv_pad (ZeroPadding2D) (None, 225, 225, 3) 0 input_1[0][0] __________________________________________________________________________________________________ stem_conv (Conv2D) (None, 112, 112, 32) 864 stem_conv_pad[0][0] __________________________________________________________________________________________________ stem_bn (BatchNormalization) (None, 112, 112, 32) 128 stem_conv[0][0] __________________________________________________________________________________________________ stem_activation (Activation) (None, 112, 112, 32) 0 stem_bn[0][0] __________________________________________________________________________________________________ block1a_dwconv (DepthwiseConv2D (None, 112, 112, 32) 288 stem_activation[0][0] __________________________________________________________________________________________________ block1a_bn (BatchNormalization) (None, 112, 112, 32) 128 block1a_dwconv[0][0] __________________________________________________________________________________________________ block1a_activation (Activation) (None, 112, 112, 32) 0 block1a_bn[0][0] __________________________________________________________________________________________________ block1a_se_squeeze (GlobalAvera (None, 32) 0 block1a_activation[0][0] __________________________________________________________________________________________________ block1a_se_reshape (Reshape) (None, 1, 1, 32) 0 block1a_se_squeeze[0][0] __________________________________________________________________________________________________ block1a_se_reduce (Conv2D) (None, 1, 1, 8) 264 block1a_se_reshape[0][0] __________________________________________________________________________________________________ block1a_se_expand (Conv2D) (None, 1, 1, 32) 288 block1a_se_reduce[0][0] __________________________________________________________________________________________________ block1a_se_excite (Multiply) (None, 112, 112, 32) 0 block1a_activation[0][0] block1a_se_expand[0][0] __________________________________________________________________________________________________ block1a_project_conv (Conv2D) (None, 112, 112, 16) 512 block1a_se_excite[0][0] __________________________________________________________________________________________________ block1a_project_bn (BatchNormal (None, 112, 112, 16) 64 block1a_project_conv[0][0] __________________________________________________________________________________________________ block2a_expand_conv (Conv2D) (None, 112, 112, 96) 1536 block1a_project_bn[0][0] __________________________________________________________________________________________________ block2a_expand_bn (BatchNormali (None, 112, 112, 96) 384 block2a_expand_conv[0][0] __________________________________________________________________________________________________ block2a_expand_activation (Acti (None, 112, 112, 96) 0 block2a_expand_bn[0][0] __________________________________________________________________________________________________ block2a_dwconv_pad (ZeroPadding (None, 113, 113, 96) 0 block2a_expand_activation[0][0] __________________________________________________________________________________________________ block2a_dwconv (DepthwiseConv2D (None, 56, 56, 96) 864 block2a_dwconv_pad[0][0] __________________________________________________________________________________________________ block2a_bn (BatchNormalization) (None, 56, 56, 96) 384 block2a_dwconv[0][0] __________________________________________________________________________________________________ block2a_activation (Activation) (None, 56, 56, 96) 0 block2a_bn[0][0] __________________________________________________________________________________________________ block2a_se_squeeze (GlobalAvera (None, 96) 0 block2a_activation[0][0] __________________________________________________________________________________________________ block2a_se_reshape (Reshape) (None, 1, 1, 96) 0 block2a_se_squeeze[0][0] __________________________________________________________________________________________________ block2a_se_reduce (Conv2D) (None, 1, 1, 4) 388 block2a_se_reshape[0][0] __________________________________________________________________________________________________ block2a_se_expand (Conv2D) (None, 1, 1, 96) 480 block2a_se_reduce[0][0] __________________________________________________________________________________________________ block2a_se_excite (Multiply) (None, 56, 56, 96) 0 block2a_activation[0][0] block2a_se_expand[0][0] __________________________________________________________________________________________________ block2a_project_conv (Conv2D) (None, 56, 56, 24) 2304 block2a_se_excite[0][0] __________________________________________________________________________________________________ block2a_project_bn (BatchNormal (None, 56, 56, 24) 96 block2a_project_conv[0][0] __________________________________________________________________________________________________ block2b_expand_conv (Conv2D) (None, 56, 56, 144) 3456 block2a_project_bn[0][0] __________________________________________________________________________________________________ block2b_expand_bn (BatchNormali (None, 56, 56, 144) 576 block2b_expand_conv[0][0] __________________________________________________________________________________________________ block2b_expand_activation (Acti (None, 56, 56, 144) 0 block2b_expand_bn[0][0] __________________________________________________________________________________________________ block2b_dwconv (DepthwiseConv2D (None, 56, 56, 144) 1296 block2b_expand_activation[0][0] __________________________________________________________________________________________________ block2b_bn (BatchNormalization) (None, 56, 56, 144) 576 block2b_dwconv[0][0] __________________________________________________________________________________________________ block2b_activation (Activation) (None, 56, 56, 144) 0 block2b_bn[0][0] __________________________________________________________________________________________________ block2b_se_squeeze (GlobalAvera (None, 144) 0 block2b_activation[0][0] __________________________________________________________________________________________________ block2b_se_reshape (Reshape) (None, 1, 1, 144) 0 block2b_se_squeeze[0][0] __________________________________________________________________________________________________ block2b_se_reduce (Conv2D) (None, 1, 1, 6) 870 block2b_se_reshape[0][0] __________________________________________________________________________________________________ block2b_se_expand (Conv2D) (None, 1, 1, 144) 1008 block2b_se_reduce[0][0] __________________________________________________________________________________________________ block2b_se_excite (Multiply) (None, 56, 56, 144) 0 block2b_activation[0][0] block2b_se_expand[0][0] __________________________________________________________________________________________________ block2b_project_conv (Conv2D) (None, 56, 56, 24) 3456 block2b_se_excite[0][0] __________________________________________________________________________________________________ block2b_project_bn (BatchNormal (None, 56, 56, 24) 96 block2b_project_conv[0][0] __________________________________________________________________________________________________ block2b_drop (Dropout) (None, 56, 56, 24) 0 block2b_project_bn[0][0] __________________________________________________________________________________________________ block2b_add (Add) (None, 56, 56, 24) 0 block2b_drop[0][0] block2a_project_bn[0][0] __________________________________________________________________________________________________ block3a_expand_conv (Conv2D) (None, 56, 56, 144) 3456 block2b_add[0][0] __________________________________________________________________________________________________ block3a_expand_bn (BatchNormali (None, 56, 56, 144) 576 block3a_expand_conv[0][0] __________________________________________________________________________________________________ block3a_expand_activation (Acti (None, 56, 56, 144) 0 block3a_expand_bn[0][0] __________________________________________________________________________________________________ block3a_dwconv_pad (ZeroPadding (None, 59, 59, 144) 0 block3a_expand_activation[0][0] __________________________________________________________________________________________________ block3a_dwconv (DepthwiseConv2D (None, 28, 28, 144) 3600 block3a_dwconv_pad[0][0] __________________________________________________________________________________________________ block3a_bn (BatchNormalization) (None, 28, 28, 144) 576 block3a_dwconv[0][0] __________________________________________________________________________________________________ block3a_activation (Activation) (None, 28, 28, 144) 0 block3a_bn[0][0] __________________________________________________________________________________________________ block3a_se_squeeze (GlobalAvera (None, 144) 0 block3a_activation[0][0] __________________________________________________________________________________________________ block3a_se_reshape (Reshape) (None, 1, 1, 144) 0 block3a_se_squeeze[0][0] __________________________________________________________________________________________________ block3a_se_reduce (Conv2D) (None, 1, 1, 6) 870 block3a_se_reshape[0][0] __________________________________________________________________________________________________ block3a_se_expand (Conv2D) (None, 1, 1, 144) 1008 block3a_se_reduce[0][0] __________________________________________________________________________________________________ block3a_se_excite (Multiply) (None, 28, 28, 144) 0 block3a_activation[0][0] block3a_se_expand[0][0] __________________________________________________________________________________________________ block3a_project_conv (Conv2D) (None, 28, 28, 40) 5760 block3a_se_excite[0][0] __________________________________________________________________________________________________ block3a_project_bn (BatchNormal (None, 28, 28, 40) 160 block3a_project_conv[0][0] __________________________________________________________________________________________________ block3b_expand_conv (Conv2D) (None, 28, 28, 240) 9600 block3a_project_bn[0][0] __________________________________________________________________________________________________ block3b_expand_bn (BatchNormali (None, 28, 28, 240) 960 block3b_expand_conv[0][0] __________________________________________________________________________________________________ block3b_expand_activation (Acti (None, 28, 28, 240) 0 block3b_expand_bn[0][0] __________________________________________________________________________________________________ block3b_dwconv (DepthwiseConv2D (None, 28, 28, 240) 6000 block3b_expand_activation[0][0] __________________________________________________________________________________________________ block3b_bn (BatchNormalization) (None, 28, 28, 240) 960 block3b_dwconv[0][0] __________________________________________________________________________________________________ block3b_activation (Activation) (None, 28, 28, 240) 0 block3b_bn[0][0] __________________________________________________________________________________________________ block3b_se_squeeze (GlobalAvera (None, 240) 0 block3b_activation[0][0] __________________________________________________________________________________________________ block3b_se_reshape (Reshape) (None, 1, 1, 240) 0 block3b_se_squeeze[0][0] __________________________________________________________________________________________________ block3b_se_reduce (Conv2D) (None, 1, 1, 10) 2410 block3b_se_reshape[0][0] __________________________________________________________________________________________________ block3b_se_expand (Conv2D) (None, 1, 1, 240) 2640 block3b_se_reduce[0][0] __________________________________________________________________________________________________ block3b_se_excite (Multiply) (None, 28, 28, 240) 0 block3b_activation[0][0] block3b_se_expand[0][0] __________________________________________________________________________________________________ block3b_project_conv (Conv2D) (None, 28, 28, 40) 9600 block3b_se_excite[0][0] __________________________________________________________________________________________________ block3b_project_bn (BatchNormal (None, 28, 28, 40) 160 block3b_project_conv[0][0] __________________________________________________________________________________________________ block3b_drop (Dropout) (None, 28, 28, 40) 0 block3b_project_bn[0][0] __________________________________________________________________________________________________ block3b_add (Add) (None, 28, 28, 40) 0 block3b_drop[0][0] block3a_project_bn[0][0] __________________________________________________________________________________________________ block4a_expand_conv (Conv2D) (None, 28, 28, 240) 9600 block3b_add[0][0] __________________________________________________________________________________________________ block4a_expand_bn (BatchNormali (None, 28, 28, 240) 960 block4a_expand_conv[0][0] __________________________________________________________________________________________________ block4a_expand_activation (Acti (None, 28, 28, 240) 0 block4a_expand_bn[0][0] __________________________________________________________________________________________________ block4a_dwconv_pad (ZeroPadding (None, 29, 29, 240) 0 block4a_expand_activation[0][0] __________________________________________________________________________________________________ block4a_dwconv (DepthwiseConv2D (None, 14, 14, 240) 2160 block4a_dwconv_pad[0][0] __________________________________________________________________________________________________ block4a_bn (BatchNormalization) (None, 14, 14, 240) 960 block4a_dwconv[0][0] __________________________________________________________________________________________________ block4a_activation (Activation) (None, 14, 14, 240) 0 block4a_bn[0][0] __________________________________________________________________________________________________ block4a_se_squeeze (GlobalAvera (None, 240) 0 block4a_activation[0][0] __________________________________________________________________________________________________ block4a_se_reshape (Reshape) (None, 1, 1, 240) 0 block4a_se_squeeze[0][0] __________________________________________________________________________________________________ block4a_se_reduce (Conv2D) (None, 1, 1, 10) 2410 block4a_se_reshape[0][0] __________________________________________________________________________________________________ block4a_se_expand (Conv2D) (None, 1, 1, 240) 2640 block4a_se_reduce[0][0] __________________________________________________________________________________________________ block4a_se_excite (Multiply) (None, 14, 14, 240) 0 block4a_activation[0][0] block4a_se_expand[0][0] __________________________________________________________________________________________________ block4a_project_conv (Conv2D) (None, 14, 14, 80) 19200 block4a_se_excite[0][0] __________________________________________________________________________________________________ block4a_project_bn (BatchNormal (None, 14, 14, 80) 320 block4a_project_conv[0][0] __________________________________________________________________________________________________ block4b_expand_conv (Conv2D) (None, 14, 14, 480) 38400 block4a_project_bn[0][0] __________________________________________________________________________________________________ block4b_expand_bn (BatchNormali (None, 14, 14, 480) 1920 block4b_expand_conv[0][0] __________________________________________________________________________________________________ block4b_expand_activation (Acti (None, 14, 14, 480) 0 block4b_expand_bn[0][0] __________________________________________________________________________________________________ block4b_dwconv (DepthwiseConv2D (None, 14, 14, 480) 4320 block4b_expand_activation[0][0] __________________________________________________________________________________________________ block4b_bn (BatchNormalization) (None, 14, 14, 480) 1920 block4b_dwconv[0][0] __________________________________________________________________________________________________ block4b_activation (Activation) (None, 14, 14, 480) 0 block4b_bn[0][0] __________________________________________________________________________________________________ block4b_se_squeeze (GlobalAvera (None, 480) 0 block4b_activation[0][0] __________________________________________________________________________________________________ block4b_se_reshape (Reshape) (None, 1, 1, 480) 0 block4b_se_squeeze[0][0] __________________________________________________________________________________________________ block4b_se_reduce (Conv2D) (None, 1, 1, 20) 9620 block4b_se_reshape[0][0] __________________________________________________________________________________________________ block4b_se_expand (Conv2D) (None, 1, 1, 480) 10080 block4b_se_reduce[0][0] __________________________________________________________________________________________________ block4b_se_excite (Multiply) (None, 14, 14, 480) 0 block4b_activation[0][0] block4b_se_expand[0][0] __________________________________________________________________________________________________ block4b_project_conv (Conv2D) (None, 14, 14, 80) 38400 block4b_se_excite[0][0] __________________________________________________________________________________________________ block4b_project_bn (BatchNormal (None, 14, 14, 80) 320 block4b_project_conv[0][0] __________________________________________________________________________________________________ block4b_drop (Dropout) (None, 14, 14, 80) 0 block4b_project_bn[0][0] __________________________________________________________________________________________________ block4b_add (Add) (None, 14, 14, 80) 0 block4b_drop[0][0] block4a_project_bn[0][0] __________________________________________________________________________________________________ block4c_expand_conv (Conv2D) (None, 14, 14, 480) 38400 block4b_add[0][0] __________________________________________________________________________________________________ block4c_expand_bn (BatchNormali (None, 14, 14, 480) 1920 block4c_expand_conv[0][0] __________________________________________________________________________________________________ block4c_expand_activation (Acti (None, 14, 14, 480) 0 block4c_expand_bn[0][0] __________________________________________________________________________________________________ block4c_dwconv (DepthwiseConv2D (None, 14, 14, 480) 4320 block4c_expand_activation[0][0] __________________________________________________________________________________________________ block4c_bn (BatchNormalization) (None, 14, 14, 480) 1920 block4c_dwconv[0][0] __________________________________________________________________________________________________ block4c_activation (Activation) (None, 14, 14, 480) 0 block4c_bn[0][0] __________________________________________________________________________________________________ block4c_se_squeeze (GlobalAvera (None, 480) 0 block4c_activation[0][0] __________________________________________________________________________________________________ block4c_se_reshape (Reshape) (None, 1, 1, 480) 0 block4c_se_squeeze[0][0] __________________________________________________________________________________________________ block4c_se_reduce (Conv2D) (None, 1, 1, 20) 9620 block4c_se_reshape[0][0] __________________________________________________________________________________________________ block4c_se_expand (Conv2D) (None, 1, 1, 480) 10080 block4c_se_reduce[0][0] __________________________________________________________________________________________________ block4c_se_excite (Multiply) (None, 14, 14, 480) 0 block4c_activation[0][0] block4c_se_expand[0][0] __________________________________________________________________________________________________ block4c_project_conv (Conv2D) (None, 14, 14, 80) 38400 block4c_se_excite[0][0] __________________________________________________________________________________________________ block4c_project_bn (BatchNormal (None, 14, 14, 80) 320 block4c_project_conv[0][0] __________________________________________________________________________________________________ block4c_drop (Dropout) (None, 14, 14, 80) 0 block4c_project_bn[0][0] __________________________________________________________________________________________________ block4c_add (Add) (None, 14, 14, 80) 0 block4c_drop[0][0] block4b_add[0][0] __________________________________________________________________________________________________ block5a_expand_conv (Conv2D) (None, 14, 14, 480) 38400 block4c_add[0][0] __________________________________________________________________________________________________ block5a_expand_bn (BatchNormali (None, 14, 14, 480) 1920 block5a_expand_conv[0][0] __________________________________________________________________________________________________ block5a_expand_activation (Acti (None, 14, 14, 480) 0 block5a_expand_bn[0][0] __________________________________________________________________________________________________ block5a_dwconv (DepthwiseConv2D (None, 14, 14, 480) 12000 block5a_expand_activation[0][0] __________________________________________________________________________________________________ block5a_bn (BatchNormalization) (None, 14, 14, 480) 1920 block5a_dwconv[0][0] __________________________________________________________________________________________________ block5a_activation (Activation) (None, 14, 14, 480) 0 block5a_bn[0][0] __________________________________________________________________________________________________ block5a_se_squeeze (GlobalAvera (None, 480) 0 block5a_activation[0][0] __________________________________________________________________________________________________ block5a_se_reshape (Reshape) (None, 1, 1, 480) 0 block5a_se_squeeze[0][0] __________________________________________________________________________________________________ block5a_se_reduce (Conv2D) (None, 1, 1, 20) 9620 block5a_se_reshape[0][0] __________________________________________________________________________________________________ block5a_se_expand (Conv2D) (None, 1, 1, 480) 10080 block5a_se_reduce[0][0] __________________________________________________________________________________________________ block5a_se_excite (Multiply) (None, 14, 14, 480) 0 block5a_activation[0][0] block5a_se_expand[0][0] __________________________________________________________________________________________________ block5a_project_conv (Conv2D) (None, 14, 14, 112) 53760 block5a_se_excite[0][0] __________________________________________________________________________________________________ block5a_project_bn (BatchNormal (None, 14, 14, 112) 448 block5a_project_conv[0][0] __________________________________________________________________________________________________ block5b_expand_conv (Conv2D) (None, 14, 14, 672) 75264 block5a_project_bn[0][0] __________________________________________________________________________________________________ block5b_expand_bn (BatchNormali (None, 14, 14, 672) 2688 block5b_expand_conv[0][0] __________________________________________________________________________________________________ block5b_expand_activation (Acti (None, 14, 14, 672) 0 block5b_expand_bn[0][0] __________________________________________________________________________________________________ block5b_dwconv (DepthwiseConv2D (None, 14, 14, 672) 16800 block5b_expand_activation[0][0] __________________________________________________________________________________________________ block5b_bn (BatchNormalization) (None, 14, 14, 672) 2688 block5b_dwconv[0][0] __________________________________________________________________________________________________ block5b_activation (Activation) (None, 14, 14, 672) 0 block5b_bn[0][0] __________________________________________________________________________________________________ block5b_se_squeeze (GlobalAvera (None, 672) 0 block5b_activation[0][0] __________________________________________________________________________________________________ block5b_se_reshape (Reshape) (None, 1, 1, 672) 0 block5b_se_squeeze[0][0] __________________________________________________________________________________________________ block5b_se_reduce (Conv2D) (None, 1, 1, 28) 18844 block5b_se_reshape[0][0] __________________________________________________________________________________________________ block5b_se_expand (Conv2D) (None, 1, 1, 672) 19488 block5b_se_reduce[0][0] __________________________________________________________________________________________________ block5b_se_excite (Multiply) (None, 14, 14, 672) 0 block5b_activation[0][0] block5b_se_expand[0][0] __________________________________________________________________________________________________ block5b_project_conv (Conv2D) (None, 14, 14, 112) 75264 block5b_se_excite[0][0] __________________________________________________________________________________________________ block5b_project_bn (BatchNormal (None, 14, 14, 112) 448 block5b_project_conv[0][0] __________________________________________________________________________________________________ block5b_drop (Dropout) (None, 14, 14, 112) 0 block5b_project_bn[0][0] __________________________________________________________________________________________________ block5b_add (Add) (None, 14, 14, 112) 0 block5b_drop[0][0] block5a_project_bn[0][0] __________________________________________________________________________________________________ block5c_expand_conv (Conv2D) (None, 14, 14, 672) 75264 block5b_add[0][0] __________________________________________________________________________________________________ block5c_expand_bn (BatchNormali (None, 14, 14, 672) 2688 block5c_expand_conv[0][0] __________________________________________________________________________________________________ block5c_expand_activation (Acti (None, 14, 14, 672) 0 block5c_expand_bn[0][0] __________________________________________________________________________________________________ block5c_dwconv (DepthwiseConv2D (None, 14, 14, 672) 16800 block5c_expand_activation[0][0] __________________________________________________________________________________________________ block5c_bn (BatchNormalization) (None, 14, 14, 672) 2688 block5c_dwconv[0][0] __________________________________________________________________________________________________ block5c_activation (Activation) (None, 14, 14, 672) 0 block5c_bn[0][0] __________________________________________________________________________________________________ block5c_se_squeeze (GlobalAvera (None, 672) 0 block5c_activation[0][0] __________________________________________________________________________________________________ block5c_se_reshape (Reshape) (None, 1, 1, 672) 0 block5c_se_squeeze[0][0] __________________________________________________________________________________________________ block5c_se_reduce (Conv2D) (None, 1, 1, 28) 18844 block5c_se_reshape[0][0] __________________________________________________________________________________________________ block5c_se_expand (Conv2D) (None, 1, 1, 672) 19488 block5c_se_reduce[0][0] __________________________________________________________________________________________________ block5c_se_excite (Multiply) (None, 14, 14, 672) 0 block5c_activation[0][0] block5c_se_expand[0][0] __________________________________________________________________________________________________ block5c_project_conv (Conv2D) (None, 14, 14, 112) 75264 block5c_se_excite[0][0] __________________________________________________________________________________________________ block5c_project_bn (BatchNormal (None, 14, 14, 112) 448 block5c_project_conv[0][0] __________________________________________________________________________________________________ block5c_drop (Dropout) (None, 14, 14, 112) 0 block5c_project_bn[0][0] __________________________________________________________________________________________________ block5c_add (Add) (None, 14, 14, 112) 0 block5c_drop[0][0] block5b_add[0][0] __________________________________________________________________________________________________ block6a_expand_conv (Conv2D) (None, 14, 14, 672) 75264 block5c_add[0][0] __________________________________________________________________________________________________ block6a_expand_bn (BatchNormali (None, 14, 14, 672) 2688 block6a_expand_conv[0][0] __________________________________________________________________________________________________ block6a_expand_activation (Acti (None, 14, 14, 672) 0 block6a_expand_bn[0][0] __________________________________________________________________________________________________ block6a_dwconv_pad (ZeroPadding (None, 17, 17, 672) 0 block6a_expand_activation[0][0] __________________________________________________________________________________________________ block6a_dwconv (DepthwiseConv2D (None, 7, 7, 672) 16800 block6a_dwconv_pad[0][0] __________________________________________________________________________________________________ block6a_bn (BatchNormalization) (None, 7, 7, 672) 2688 block6a_dwconv[0][0] __________________________________________________________________________________________________ block6a_activation (Activation) (None, 7, 7, 672) 0 block6a_bn[0][0] __________________________________________________________________________________________________ block6a_se_squeeze (GlobalAvera (None, 672) 0 block6a_activation[0][0] __________________________________________________________________________________________________ block6a_se_reshape (Reshape) (None, 1, 1, 672) 0 block6a_se_squeeze[0][0] __________________________________________________________________________________________________ block6a_se_reduce (Conv2D) (None, 1, 1, 28) 18844 block6a_se_reshape[0][0] __________________________________________________________________________________________________ block6a_se_expand (Conv2D) (None, 1, 1, 672) 19488 block6a_se_reduce[0][0] __________________________________________________________________________________________________ block6a_se_excite (Multiply) (None, 7, 7, 672) 0 block6a_activation[0][0] block6a_se_expand[0][0] __________________________________________________________________________________________________ block6a_project_conv (Conv2D) (None, 7, 7, 192) 129024 block6a_se_excite[0][0] __________________________________________________________________________________________________ block6a_project_bn (BatchNormal (None, 7, 7, 192) 768 block6a_project_conv[0][0] __________________________________________________________________________________________________ block6b_expand_conv (Conv2D) (None, 7, 7, 1152) 221184 block6a_project_bn[0][0] __________________________________________________________________________________________________ block6b_expand_bn (BatchNormali (None, 7, 7, 1152) 4608 block6b_expand_conv[0][0] __________________________________________________________________________________________________ block6b_expand_activation (Acti (None, 7, 7, 1152) 0 block6b_expand_bn[0][0] __________________________________________________________________________________________________ block6b_dwconv (DepthwiseConv2D (None, 7, 7, 1152) 28800 block6b_expand_activation[0][0] __________________________________________________________________________________________________ block6b_bn (BatchNormalization) (None, 7, 7, 1152) 4608 block6b_dwconv[0][0] __________________________________________________________________________________________________ block6b_activation (Activation) (None, 7, 7, 1152) 0 block6b_bn[0][0] __________________________________________________________________________________________________ block6b_se_squeeze (GlobalAvera (None, 1152) 0 block6b_activation[0][0] __________________________________________________________________________________________________ block6b_se_reshape (Reshape) (None, 1, 1, 1152) 0 block6b_se_squeeze[0][0] __________________________________________________________________________________________________ block6b_se_reduce (Conv2D) (None, 1, 1, 48) 55344 block6b_se_reshape[0][0] __________________________________________________________________________________________________ block6b_se_expand (Conv2D) (None, 1, 1, 1152) 56448 block6b_se_reduce[0][0] __________________________________________________________________________________________________ block6b_se_excite (Multiply) (None, 7, 7, 1152) 0 block6b_activation[0][0] block6b_se_expand[0][0] __________________________________________________________________________________________________ block6b_project_conv (Conv2D) (None, 7, 7, 192) 221184 block6b_se_excite[0][0] __________________________________________________________________________________________________ block6b_project_bn (BatchNormal (None, 7, 7, 192) 768 block6b_project_conv[0][0] __________________________________________________________________________________________________ block6b_drop (Dropout) (None, 7, 7, 192) 0 block6b_project_bn[0][0] __________________________________________________________________________________________________ block6b_add (Add) (None, 7, 7, 192) 0 block6b_drop[0][0] block6a_project_bn[0][0] __________________________________________________________________________________________________ block6c_expand_conv (Conv2D) (None, 7, 7, 1152) 221184 block6b_add[0][0] __________________________________________________________________________________________________ block6c_expand_bn (BatchNormali (None, 7, 7, 1152) 4608 block6c_expand_conv[0][0] __________________________________________________________________________________________________ block6c_expand_activation (Acti (None, 7, 7, 1152) 0 block6c_expand_bn[0][0] __________________________________________________________________________________________________ block6c_dwconv (DepthwiseConv2D (None, 7, 7, 1152) 28800 block6c_expand_activation[0][0] __________________________________________________________________________________________________ block6c_bn (BatchNormalization) (None, 7, 7, 1152) 4608 block6c_dwconv[0][0] __________________________________________________________________________________________________ block6c_activation (Activation) (None, 7, 7, 1152) 0 block6c_bn[0][0] __________________________________________________________________________________________________ block6c_se_squeeze (GlobalAvera (None, 1152) 0 block6c_activation[0][0] __________________________________________________________________________________________________ block6c_se_reshape (Reshape) (None, 1, 1, 1152) 0 block6c_se_squeeze[0][0] __________________________________________________________________________________________________ block6c_se_reduce (Conv2D) (None, 1, 1, 48) 55344 block6c_se_reshape[0][0] __________________________________________________________________________________________________ block6c_se_expand (Conv2D) (None, 1, 1, 1152) 56448 block6c_se_reduce[0][0] __________________________________________________________________________________________________ block6c_se_excite (Multiply) (None, 7, 7, 1152) 0 block6c_activation[0][0] block6c_se_expand[0][0] __________________________________________________________________________________________________ block6c_project_conv (Conv2D) (None, 7, 7, 192) 221184 block6c_se_excite[0][0] __________________________________________________________________________________________________ block6c_project_bn (BatchNormal (None, 7, 7, 192) 768 block6c_project_conv[0][0] __________________________________________________________________________________________________ block6c_drop (Dropout) (None, 7, 7, 192) 0 block6c_project_bn[0][0] __________________________________________________________________________________________________ block6c_add (Add) (None, 7, 7, 192) 0 block6c_drop[0][0] block6b_add[0][0] __________________________________________________________________________________________________ block6d_expand_conv (Conv2D) (None, 7, 7, 1152) 221184 block6c_add[0][0] __________________________________________________________________________________________________ block6d_expand_bn (BatchNormali (None, 7, 7, 1152) 4608 block6d_expand_conv[0][0] __________________________________________________________________________________________________ block6d_expand_activation (Acti (None, 7, 7, 1152) 0 block6d_expand_bn[0][0] __________________________________________________________________________________________________ block6d_dwconv (DepthwiseConv2D (None, 7, 7, 1152) 28800 block6d_expand_activation[0][0] __________________________________________________________________________________________________ block6d_bn (BatchNormalization) (None, 7, 7, 1152) 4608 block6d_dwconv[0][0] __________________________________________________________________________________________________ block6d_activation (Activation) (None, 7, 7, 1152) 0 block6d_bn[0][0] __________________________________________________________________________________________________ block6d_se_squeeze (GlobalAvera (None, 1152) 0 block6d_activation[0][0] __________________________________________________________________________________________________ block6d_se_reshape (Reshape) (None, 1, 1, 1152) 0 block6d_se_squeeze[0][0] __________________________________________________________________________________________________ block6d_se_reduce (Conv2D) (None, 1, 1, 48) 55344 block6d_se_reshape[0][0] __________________________________________________________________________________________________ block6d_se_expand (Conv2D) (None, 1, 1, 1152) 56448 block6d_se_reduce[0][0] __________________________________________________________________________________________________ block6d_se_excite (Multiply) (None, 7, 7, 1152) 0 block6d_activation[0][0] block6d_se_expand[0][0] __________________________________________________________________________________________________ block6d_project_conv (Conv2D) (None, 7, 7, 192) 221184 block6d_se_excite[0][0] __________________________________________________________________________________________________ block6d_project_bn (BatchNormal (None, 7, 7, 192) 768 block6d_project_conv[0][0] __________________________________________________________________________________________________ block6d_drop (Dropout) (None, 7, 7, 192) 0 block6d_project_bn[0][0] __________________________________________________________________________________________________ block6d_add (Add) (None, 7, 7, 192) 0 block6d_drop[0][0] block6c_add[0][0] __________________________________________________________________________________________________ block7a_expand_conv (Conv2D) (None, 7, 7, 1152) 221184 block6d_add[0][0] __________________________________________________________________________________________________ block7a_expand_bn (BatchNormali (None, 7, 7, 1152) 4608 block7a_expand_conv[0][0] __________________________________________________________________________________________________ block7a_expand_activation (Acti (None, 7, 7, 1152) 0 block7a_expand_bn[0][0] __________________________________________________________________________________________________ block7a_dwconv (DepthwiseConv2D (None, 7, 7, 1152) 10368 block7a_expand_activation[0][0] __________________________________________________________________________________________________ block7a_bn (BatchNormalization) (None, 7, 7, 1152) 4608 block7a_dwconv[0][0] __________________________________________________________________________________________________ block7a_activation (Activation) (None, 7, 7, 1152) 0 block7a_bn[0][0] __________________________________________________________________________________________________ block7a_se_squeeze (GlobalAvera (None, 1152) 0 block7a_activation[0][0] __________________________________________________________________________________________________ block7a_se_reshape (Reshape) (None, 1, 1, 1152) 0 block7a_se_squeeze[0][0] __________________________________________________________________________________________________ block7a_se_reduce (Conv2D) (None, 1, 1, 48) 55344 block7a_se_reshape[0][0] __________________________________________________________________________________________________ block7a_se_expand (Conv2D) (None, 1, 1, 1152) 56448 block7a_se_reduce[0][0] __________________________________________________________________________________________________ block7a_se_excite (Multiply) (None, 7, 7, 1152) 0 block7a_activation[0][0] block7a_se_expand[0][0] __________________________________________________________________________________________________ block7a_project_conv (Conv2D) (None, 7, 7, 320) 368640 block7a_se_excite[0][0] __________________________________________________________________________________________________ block7a_project_bn (BatchNormal (None, 7, 7, 320) 1280 block7a_project_conv[0][0] __________________________________________________________________________________________________ top_conv (Conv2D) (None, 7, 7, 1280) 409600 block7a_project_bn[0][0] __________________________________________________________________________________________________ top_bn (BatchNormalization) (None, 7, 7, 1280) 5120 top_conv[0][0] __________________________________________________________________________________________________ top_activation (Activation) (None, 7, 7, 1280) 0 top_bn[0][0] __________________________________________________________________________________________________ global_average_pooling2d (Globa (None, 1280) 0 top_activation[0][0] __________________________________________________________________________________________________ flatten (Flatten) (None, 1280) 0 global_average_pooling2d[0][0] __________________________________________________________________________________________________ dense (Dense) (None, 10) 12810 flatten[0][0] ================================================================================================== Total params: 4,062,374 Trainable params: 12,810 Non-trainable params: 4,049,564 __________________________________________________________________________________________________ . 6) Train/fit model to dataset . num_epochs = 5 history = new_model.fit(train_it, validation_data = val_it, epochs=num_epochs, verbose = 1) . WARNING:tensorflow:sample_weight modes were coerced from ... to [&#39;...&#39;] WARNING:tensorflow:sample_weight modes were coerced from ... to [&#39;...&#39;] Train for 296 steps, validate for 123 steps Epoch 1/5 296/296 [==============================] - 83s 279ms/step - loss: 0.3098 - accuracy: 0.9354 - val_loss: 0.0925 - val_accuracy: 0.9786 Epoch 2/5 296/296 [==============================] - 60s 204ms/step - loss: 0.0836 - accuracy: 0.9781 - val_loss: 0.0670 - val_accuracy: 0.9829 Epoch 3/5 296/296 [==============================] - 61s 206ms/step - loss: 0.0622 - accuracy: 0.9837 - val_loss: 0.0586 - val_accuracy: 0.9811 Epoch 4/5 296/296 [==============================] - 62s 208ms/step - loss: 0.0483 - accuracy: 0.9867 - val_loss: 0.0541 - val_accuracy: 0.9845 Epoch 5/5 296/296 [==============================] - 62s 209ms/step - loss: 0.0369 - accuracy: 0.9917 - val_loss: 0.0523 - val_accuracy: 0.9839 . 7) Plot Training/Validation History . acc = history.history[&#39;accuracy&#39;] val_acc = history.history[&#39;val_accuracy&#39;] loss = history.history[&#39;loss&#39;] val_loss = history.history[&#39;val_loss&#39;] epochs = range(len(acc)) plt.subplot(121) plt.plot(epochs, acc, &#39;b&#39;, label=&#39;Training Acc&#39;) plt.plot(epochs, val_acc, &#39;r&#39;, label=&#39;Validation Acc&#39;) plt.title(&#39;Train/Val Accuracy&#39;) plt.legend() plt.subplot(122) plt.plot(epochs, loss, &#39;b&#39;, label=&#39;Training Loss&#39;) plt.plot(epochs, val_loss, &#39;r&#39;, label=&#39;Validation Loss&#39;) plt.title(&#39;Train/Val Loss&#39;) plt.legend() plt.show() .",
            "url": "https://datadote.github.io/blog/2020/05/02/2020-03-15-transfer_learning_efficientNet.html",
            "relUrl": "/2020/05/02/2020-03-15-transfer_learning_efficientNet.html",
            "date": " • May 2, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Fastbook_ch8_ans",
            "content": "Chapter 8 Answers . What problem does collaborative filtering solve? Bring recommendations to users . | How does it solve it? Create an embedding vector for users and items, and then compare vector distances . | Why might a collaborative filtering predictive model fail to be a very useful recommendation system? If there is a positive feedback loop that reinforces a small group. For example, anime watchers watch a lot of anime, and the recommender may bias towards anime . | What does a crosstab representation of collaborative filtering data look like? Left side y axis represents users+user_embeddings, x axis represents items+item_embeddings. The cross section represents the dependent variable . | Write the code to create a crosstab representation of the MovieLens data (you might need to do some web searching!) *** Not done . | What is a latent factor? Why is it “latent”? Latent factor are indirect variables, not directly observed, but seen through a combination of other variables. Latent means hidden or concealed . | What is a dot product? Calculate a dot product manually using pure python with lists. Dot product is the element wise multiplication of two vectors, and then summing all the products . | What does pandas.DataFrame.merge do? Combines data frames together along, and aligns data with a specific column . | What is an embedding matrix? Embedding matrix is a matrix of users/items and latent factors . | What is the relationship between an embedding and a matrix of one-hot encoded vectors? You use the one-hot encoded vector to pull the embeddings of 1 user. You can think of an embedding as a compressed version of the one-hot encoded vectors . | Why do we need Embedding if we could use one-hot encoded vectors for the same thing? Embeddings save a lot more memory especially if the there is high cardinality. Also, embeddings allow turning categories into continuous variables . | What does an embedding contain before we start training (assuming we’re not using a prertained model)? Randomly initialized numbers . | Create a class (without peeking, if possible!) and use it. *** Not done . | What does x[:,0] return? Every row of column 0 (first column) . | Rewrite the DotProduct class (without peeking, if possible!) and train a model with it *** Not done . | What is a good loss function to use for MovieLens? Why? Mean squared error because we have a range of values (1,2,3,4,5) . | What would happen if we used CrossEntropy loss with MovieLens? How would we need to change the model? ??? It wouldn’t work because it looks for a 1 or 0. You need to do categorical cross entropy . | What is the use of bias in a dot product model? The bias centers the function in order to balance with other neurons . | What is another name for weight decay? L2 regularization . | Write the equation for weight decay (without peeking!) total_loss = loss + sum(wd*(w**2)) . | Write the equation for the gradient of weight decay. Why does it help reduce weights? weight = weight - lrgrad grad = grad + 2weight weight = weight - lr(grad + 2weight) weight = (1-2lr)weight - lr*grad . | Why does reducing weights lead to better generalization? More neurons/weights are used, and therefore have to share features among themselves versus just 1 weight . | What does argsort do in PyTorch? argsort gives you the indices of the sorted values . | Does sorting the movie biases give the same result as averaging overall movie ratings by movie? Why / why not? No, sorting the movie biases gives additional information that given a movie, the people who like that genre, may not like that movie. Whereas the overall movie rating just gives the average across people . | How do you print the names and details of the layers in a model? layer.model . | What is the “bootstrapping problem” in collaborative filtering? How to recommend things to new users who have no previous history. You can’t bootstrap them to previous knowledge, because you don’t have any . | How could you deal with the bootstrapping problem for new users? For new movies? Start people at the average, or ask questions, or get meta data . | How can feedback loops impact collaborative filtering systems? They could impact systems negatively if there is a reinforcing bias . | When using a neural network in collaborative filtering, why can we have different number of factors for movie and user? Each represent different complexities. We will flatten, and concatenate all these features before feeding into the neural network . | Why is there a nn.Sequential in the CollabNN model? To create a small NN model . | What kind of model should be use if we want to add metadata about users and items, or information such as date and time, to a collaborative filter model? EmbeddingNN, which inherits from TabularModel . |",
            "url": "https://datadote.github.io/blog/2020/05/02/fastbook_ch8_ans.html",
            "relUrl": "/2020/05/02/fastbook_ch8_ans.html",
            "date": " • May 2, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Fastbook_ch7_ans",
            "content": "Chapter 7 Answers . What is the difference between ImageNet and Imagenette? When is it better to experiment on one versus the other? Imagenet original is a dataset with ~1.3M images and 1000 classes. Imagenette is a much smaller subset of 10 distinct classes . | What is normalization? Normalization is the process of making the data input have 0 mean and std 1 . | Why didn’t we have to care about normalization when using a pretrained model? If no Normalization.from_stats() is passed to batch_tfms, FA calculates the stats from a single batch of your data . | What is progressive resizing? Training on images that gradually increase in size as training progresses. For example, first fit_one_cycle on size 128, then fine_tune on 224 . | Implement progressive resizing in your own project. Did it help? *** Did not try . | What is test time augmentation? How do you use it in fastai? TTA is when you data augment test images, and average the predictions In FA, do learn.tta(n=4) . | Is using TTA at inference slower or faster than regular inference? Why? Slower, because we need each additional image needs an inference as well . | What is Mixup? How do you use it in fastai? Mixup is when you mixup images by adding weighted versions together. This means the image pixels are added together. Weighted labels are added together as well Implemented in fa2 by adding a callback into the learner You will also want to use the LabelSmoothingCrossEntropy loss func Example: cnn_learner(dls, …, cbs = MixUp(), loss_func=LabelSmoothingCrossEntropy()) . | Why does Mixup prevent the model from being too confident? Because it allows the model to optimize predictions to values between 0, and 1. Instead of always forcing to 0/1 . | Why does a training with Mixup for 5 epochs end up worse than a training without Mixup? It is harder to see what’s in a MixUp image. Also, now it needs to predict continuous numbers instead of a 1/0 . | What is the idea behind label smoothing? If there are mislabels in your dataset, trying to optimize to 1/0 predictions can be harmful. Encourage model to be less confident by having labels between 1/0, and then adding a little “epsilon” error to every other prediction Example for one hot-encoded -&gt; [0, 1, 0, 0] -&gt; [0.1, 0.7, 0.1, 0.1] . | What problems in your data can label smoothing help with? Mislabeled data or harder to label data. I think label smoothing can give a higher fidelity to data if you start adding in prediction + confidence level For example [0, 1, 0, 0] -&gt; [0, 0.9, 0, 0] -&gt; Do you care if all sum to 1? Or just that they are constrainted between 0 and 1 (a range) . | When using label smoothing with 5 categories, what is the target associated with the index 1? 1 - epsilon + epsilon/N -&gt; where N = 5 . | What is the first step to take when you want to prototype quick experiments on a new dataset. If the dataset is large, find a smaller subset that is representative of the whole. This will let you try experiments much faster. Key is finding smallest dataset that is representative and able to discriminate between techniques For example, Imagenet (1000 classes) -&gt; Imagenette (10 classes) . |",
            "url": "https://datadote.github.io/blog/2020/04/26/fastbook_ch7_ans.html",
            "relUrl": "/2020/04/26/fastbook_ch7_ans.html",
            "date": " • Apr 26, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "Fastbook_ch6_ans",
            "content": "Chapter 6 Answers . how could multi-label classification improve the usability of the bear classifier? It could predict when there is no bear present, and not only restrict to the 3 classes . | How do we encode the dependent variable in a multi-label classification problem? One hot encoding with MultiCategoryBlock . | How do you access the rows and columns of a DataFrame as if it was a matrix? df.iloc[r,c] . | How do you get a column by name from a DataFrame? df.column or df[‘column’] . | What is the difference between a dataset and DataLoader? a dataset is a list of x,y tuples. A dataloader takes a dataset and creates + shuffles mini-batches . | What does a Datasets object normally contain? a list with 2 lists. One list is of the x input, and the other list contains the y inputs . | What does a DataLoaders object normally contain? List of Minibatch lists of (x,y) tuples . | What does lambda do in Python? Shorthand way to create functions on the fly . | What are the methods to customise how the independent and dependent variables are created with the data block API? get_x, get_y. You put in your functions base on what the dataloader input data is (eg image path vs df) . | Why is softmax not an appropriate output activation function when using a one hot encoded target? Softmax tries to maximize one output. If we have multiple labels/targets, then softmax might push labels out . | Why is nll_loss not an appropriate loss function when using a one hot encoded target? nll_loss is for single label datasets where that target is labeled as a single integer and not one-hot encoded . | What is the difference between nn.BCELoss and nn.BCEWithLogitsLoss? first one does not do a sigmoid. Second one performs a sigmoid on the activations. . | Why can’t we use regular accuracy in a multi-label problem? accuracy used predictions from the highest class, and only had 1 output. Whereas, multi-label probles have multiple outputs, and we need to check the accuracy for each class separately we will separately sigmoid each class, threshold, and then compare to target labels . | When is it okay to tune an hyper-parameter on the validation set? when the validation set accuracy sweep curve is flat -&gt; generalizes . | How is y_range implemented in fastai? (See if you can implement it yourself and test it without peaking!) y_range gives you the min and max range. Sigmoid squishes input between 0 and 1. Now, you just need to change the range -&gt; sigmoid(x)(max-min) Recenter -&gt; sigmoid(x)(max-min) + min . | What is a regression problem? What loss function should you use for such a problem? a regression problem is where the labels/targets are continuous variables. Use absolute difference or mean squared loss . | What do you need to do to make sure the fastai library applies the same data augmentation to your inputs images and your target point coordinates? Inside datatablock -&gt; blocks=(ImageBlock, PointBlock) , Pointblock lets FA know the labels are coordinates, and to perform the same augmentation as the image . |",
            "url": "https://datadote.github.io/blog/2020/04/25/fastbook_ch6_ans.html",
            "relUrl": "/2020/04/25/fastbook_ch6_ans.html",
            "date": " • Apr 25, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "Fastbook_ch5_ans",
            "content": "Chapter 5 Answers . Why do we first resize to a large size on the CPU, and then to a smaller size on the GPU? Resize to large size in order to perform augmentations. This allows margin to do augmentations without creating empty zones. Then resize to smaller size. All data augmentations, after item_tfms resize, are performed together on GPU and only have 1 interpolation step. . | If you are not familiar with regular expressions, find a regular expression tutorial, and some problem sets, and complete them. Have a look on the book website for suggestions. ** Not done . | What are the two ways in which data is most commonly provided, for most deep learning datasets? Either label in name, or labels are separated as folders. split(train,valid), then folders for each category in each folder . | Look up the documentation for L and try using a few of the new methods is that it adds. ** Not done . | Look up the documentation for the Python pathlib module and try using a few methods of the Path class. Done . | Give two examples of ways that image transformations can degrade the quality of the data. 1) Reflection padding artifacts 2) Parts of images being interpolated incorrectly . | What method does fastai provide to view the data in a DataLoader? “.show_batch()” . | What method does fastai provide to help you debug a DataBlock? “.summary() -&gt; datablock.summary(filePath_with_images)” . | Should you hold off on training a model until you have thoroughly cleaned your data? No, you can use your trained model to help you clean your data . | What are the two pieces that are combined into cross entropy loss in PyTorch? softmax and negative log likelihood log_softmax + nll_loss . | What are the two properties of activations that softmax ensures? Why is this important? softmax ensures probabilities lie between 0-1, and the sum of all the predictions = 1 . | When might you want your activations to not have these two properties? in your loss function because a 0.99 and 0.999 probability might not affect much in gradients even though 0.999 is 10x more confident than 0.99 . | Calculate the “exp” and “softmax” columns of «bear_softmax» yourself (i.e. in a spreadsheet, with a calculator, or in a notebook). Done . | Why can’t we use torch.where to create a loss function for datasets where our label can have more than two categories? torch.where finds true/false scenarios. While you could have a lot of torch.where statements, it is not as efficient as doing softmax . | What is the value of log(-2)? Why? nan or undefined because log is not defined for numbers less than or equal to 0 . | What are two good rules of thumb for picking a learning rate from the learning rate finder? Use either 10x less than the min, or use where the loss downward slope is steepest . | What two steps does the fine_tune method do? fit_one_cycle on just the head, then unfreeze all with discriminative learning rates, and fit_one_cycle . | In Jupyter notebook, how do you get the source code for a method or function? ?? before or after a function, eg ??learn.fine_tune or learn.fine_tune?? . | What are discriminative learning rates? each layer has a different learning rate. You are discriminating learning rates among the layers . | How is a Python slice object interpreted when past as a learning rate to fastai? slice(1e-6, 1e-4). First argument goes to shallowest layer. Last argument goes to deepest layer. Layers in between get a multiplicative equidistant value. . | Why is early stopping a poor choice when using one cycle training? With 1cycle training, there is a chance that early stopping picks a model before the 1cycle learning rate reaches small values. So, perhaps the accuracy lowers, increase a little, and then goes lower towards the end . | What is the difference between resnet 50 and resnet101? resnet101 has 51 more layers than resnet50 . | What does to_fp16 do? Enables calculations to use less precise numbers where possible during training Speeds up training, and reduces memory load . |",
            "url": "https://datadote.github.io/blog/2020/04/12/fastbook_ch5_ans.html",
            "relUrl": "/2020/04/12/fastbook_ch5_ans.html",
            "date": " • Apr 12, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "Fastbook_ch4_ans",
            "content": "How is a greyscale image represented on a computer? How about a color image? For greyscale, 1 number indicating range from white to black For color, 3 numbers indicating intensity of red, green, blue . | How are the files and folders in the MNIST_SAMPLE dataset structured? Why? Structured similar to imagenet Main folder -&gt; valid, train valid,train -&gt; separate folders for each category . | Explain how the “pixel similarity” approach to classifying digits works. Pixel similarity is where you find the ideal number by averaging all the images of the “number”, then you take the mean absolute difference or mean squared difference between your input and the ideal image . | What is a list comprehension? Create one now that selects odd numbers from a list and doubles them. List comprehension is a fast way to create a list from an iterator a = [x for x in range(10)]; [2*x for x in a if x%2 &gt; 0] . | What is a “rank 3 tensor”? a tensor with 3 dimensions . | What is the difference between tensor rank and shape? How do you get the rank from the shape? shape gives you information on how big each axis is. Rank is length(shape) . | What are RMSE and L1 norm? RMSE and L1 norm are methods to measure difference between two things. RMSE stands for root mean squared error. L1 norm is the mean absolute difference. . | How can you apply a calculation on thousands of numbers at once, many thousands of times faster than a Python loop? Vectorize the calculations, and then use a gpu . | Create a 3x3 tensor or array containing the numbers from 1 to 9. Double it. Select the bottom right 4 numbers. a = (torch.tensor(range(9))*2).view(3,3); a[1:3, 1:3] . | What is broadcasting? broadcasting is when a math operation happens between two inputs with different shapes (usually 1 dimension), and the smaller shape automatically becomes the shape of the larger shape . | Are metrics generally calculated using the training set, or the validation set? Why? validation set in order to make sure model is generalizing and not overfitting . | What is SGD? SGD stands for stochastic gradient descent, and is a method to optimize neural network weights. . | Why does SGD use mini batches? Speeds up training, rather than going 1 example at a time . | What are the 7 steps in SGD for machine learning? Initialize parameters, forward prop, calculate loss, backprop, update weights, repeat, stop . | How do we initialize the weights in a model? Randomly. Although with certain activations, there are certain statistics we use with the random initialization. Eg ReLU -&gt; he intialization . | What is “loss”? loss is a measure the algorithm uses to optimize itself . | Why can’t we always use a high learning rate? a high learning rate could cause the loss to increase after each update . | What is a “gradient”? gradient is the slope of a function at a point . | Do you need to know how to calculate gradients yourself? If you use a framework, no. PyTorch does it for you . | Why can’t we use accuracy as a loss function? Accuracy is not fine-grain enough. Most gradients would be close to 0, and the updating would be slow . | Draw the sigmoid function. What is special about its shape? Goes between 0 and 1. 1/(1+exp(-x)). Crosses 0.5 at x=0 . | What is the difference between loss and metric? Loss is the measure the algorithm uses to evaluate performance. Metric is what humans use. . | What is the function to calculate new weights using a learning rate? w = w - lrparams.grad, or params.data -= lrparams.grad . | What does the DataLoader class do? dataloader takes a list of tuples of (x,y), and batches/shuffles them for your model . | Write pseudo-code showing the basic steps taken each epoch for SGD. forward prop, calc loss, backprop, update weight pred = model(x) loss = loss_func(pred, y) loss.backward() p -= p.grad*lr p.grad.zero_() . | Create a function which, if passed two arguments [1,2,3,4] and &#39;abcd&#39;, returns [(1, &#39;a&#39;), (2, &#39;b&#39;), (3, &#39;c&#39;), (4, &#39;d&#39;)]. What is special about that output data structure? [x for x in zip([1,2,3,4], ‘abcd’)] . | What does view do in PyTorch? view does reshaping . | What are the “bias” parameters in a neural network? Why do we need them? bias parameters are randomly initialized parameters used in the forward prop equation. y = w*x + b. B lets the equation center itself. . | What does the @ operator do in python? @ = np.matmul = element-wise matrix multiplication . | What does the backward method do? backward calculates the gradients from the given point eg loss.backward() . | Why do we have to zero the gradients? so that the update is reflective of the current step, and not of previous steps loss.backward() accumulates gradients in each function . | What information do we have to pass to Learner? Learner(dls, net, metrics) Learner(dls, net, opt_func, loss_func, metrics) . | Show python or pseudo-code for the basic steps of a training loop. for i in range(epochs): for xb,yb in dl: calc_grad(xb, yb, model) p.data -= p.grad.data*lr p.grad.zero_() . | What is “ReLU”? Draw a plot of it for values from -2 to +2. relu(x) = max(x,0). Relu is 0 for x 0 or less, and = x for x &gt; 0 . | What is an “activation function”? activation function is a nonlinearity applied to the linear y=wx+b equation . | What’s the difference between F.relu and nn.ReLU? F.relu is the function. nn.Relu is a PyTorch module (layer) that does the same thing. . | The universal approximation theorem shows that any function can be approximated as closely as needed using just one nonlinearity. So why do we normally use more? We use more nonlinearities, which means more layers, for better performance. For the same performance, deeper networks tend to need less memory/calculations. . |",
            "url": "https://datadote.github.io/blog/2020/04/07/fastbook_ch4_ans.html",
            "relUrl": "/2020/04/07/fastbook_ch4_ans.html",
            "date": " • Apr 7, 2020"
        }
        
    
  
    
        ,"post6": {
            "title": "MNIST - Data Augmentation Gone Wrong",
            "content": "1) Import libraries, and setup file paths . #collapse-hide from fastai2.vision.all import * from utils import * path = untar_data(URLs.MNIST) train_dir = path/&#39;training&#39; #val_dir = path/&#39;testing&#39; fns_train = get_image_files(train_dir) #fns_val = get_image_files(val_dir) print(&#39;train files: &#39;, len(fns_train)) #print(&#39;val files: &#39;, len(fns_val)) . . train files: 60000 . 2) Setup two dataloaders: baseline, horizontal flip . batch_tfms = [Flip(p=1)] # horizontal flip db = DataBlock( blocks = (ImageBlock, CategoryBlock), get_items = get_image_files, splitter = RandomSplitter(valid_pct=0.2, seed=42), get_y = parent_label, batch_tfms = None ) db_flip = DataBlock( blocks = (ImageBlock, CategoryBlock), get_items = get_image_files, splitter = RandomSplitter(valid_pct=0.2, seed=42), get_y = parent_label, batch_tfms = batch_tfms ) dls = db.dataloaders(train_dir, bs=256) dls_flip = db_flip.dataloaders(train_dir, bs=256) . 3) Check each dataloader is working . dls.show_batch(ncols=5,nrows=1) . dls_flip.show_batch(ncols=5,nrows=1) . 4) Train resnet18 on baseline, and check accuracy . learn = cnn_learner(dls, resnet18, pretrained=False, metrics=accuracy) lr_min = learn.lr_find()[0] f&#39;lr_min: {lr_min:0.05f}&#39; . # no horizontal flip learn.fit_one_cycle(5, lr_min) . epoch train_loss valid_loss accuracy time . 0 | 0.207485 | 0.554384 | 0.887250 | 00:08 | . 1 | 0.106351 | 0.065353 | 0.983833 | 00:08 | . 2 | 0.073446 | 0.105541 | 0.972750 | 00:08 | . 3 | 0.039243 | 0.042821 | 0.988333 | 00:08 | . 4 | 0.017257 | 0.026517 | 0.992750 | 00:08 | . With baseline MNIST, resnet18 is getting 99% accuracy | Note: train_loss and valid_loss are both low | . 5) Train new resnet18 on horizontally flipped dataset . learn = cnn_learner(dls_flip, resnet18, pretrained=False, metrics=accuracy) lr_min = learn.lr_find()[0] f&#39;lr_min: {lr_min:0.05f}&#39; . # yes horizontal flip learn.fit_one_cycle(5, lr_min) . epoch train_loss valid_loss accuracy time . 0 | 0.215689 | 6.608447 | 0.339833 | 00:09 | . 1 | 0.098538 | 3.857758 | 0.394500 | 00:09 | . 2 | 0.076361 | 3.930472 | 0.387083 | 00:09 | . 3 | 0.040679 | 3.130253 | 0.437750 | 00:09 | . 4 | 0.015541 | 3.993914 | 0.410417 | 00:09 | . With horizontally flipped numbers, accuracy dropped to ~41% | Note, train_loss is a lot lower than valid_loss -&gt; overfitting | . 6) What happened? . interp = ClassificationInterpretation.from_learner(learn) interp.plot_top_losses(4, nrows=1) . Model is predicting a 5, when seeing a 2 | . interp.plot_confusion_matrix() . Model is predicting 0, 1, 4, and 8 correctly -&gt; 40% accuracy | Model confuses 5 for 2 | 6 for 2 | 3 for 8 | 9 for 8 | Does this make sense? | . interp.most_confused()[:5] . [(&#39;6&#39;, &#39;2&#39;, 969), (&#39;9&#39;, &#39;8&#39;, 935), (&#39;3&#39;, &#39;8&#39;, 855), (&#39;5&#39;, &#39;2&#39;, 823), (&#39;2&#39;, &#39;5&#39;, 810)] . # top number is actual, bottom number is prediction learn.show_results(max_n=12) .",
            "url": "https://datadote.github.io/blog/fastpages/jupyter/2020/04/07/Tutorial_MNIST_Data_Aug.html",
            "relUrl": "/fastpages/jupyter/2020/04/07/Tutorial_MNIST_Data_Aug.html",
            "date": " • Apr 7, 2020"
        }
        
    
  
    
        ,"post7": {
            "title": "Fastbook_ch3_ans",
            "content": "Does ethics provide a list of “right answers”? There is no list of right answers for ethics . | How can working with people of different backgrounds help when considering ethical questions? Provide different viewpoints on how an application will affect people . | What was the role of IBM in Nazi Germany? Why did the company participate as they did? Why did the workers participate? IBM provided equipment and technical assistance to classify prisoners. Company participated for money. Workers did not know better. . | What was the role of the first person jailed in the VW diesel scandal? Engineer who just did what manager told him to do. . | What was the problem with a database of suspected gang members maintained by California law enforcement officials? The database had many errors, but had no easy means of fixing the errors. The errors included 42 babies added to database then they were less than 1 year old. 28 of these babies were marked as admitting to being gang members. . | Why did YouTube’s recommendation algorithm recommend videos of partially clothed children to pedophiles, even although no employee at Google programmed this feature? The algorithm optimized itself to maximize viewer time. . | What are the problems with the centrality of metrics? Centrality of metrics, to the extreme, mean one metric is being optimized. Algorithms will try to optimize the metric without thinking about negative consequences. . | Why did Meetup.com not include gender in their recommendation system for tech meetups? More men than women were interested in tech meetups. If the recommendation system included gender, it might have increased this bias, and have a positive feedback loop. Recommend more to men, recommend less to women. . | What are the six types of bias in machine learning, according to Suresh and Guttag? Historical bias, representation bias, measurement bias, evaluation bias, aggregation bias, deployment bias . | Give two examples of historical race bias in the US Used car sales, black people offered higher initial prices. Craigslist rental-ads, Black name elicited fewer respones than a white name. . | Where are most images in Imagenet from? United States and other Western countries. Eg Great Britain, Itality, Canada, Australia, Spain. . | In the paper “Does Machine Learning Automate Moral Hazard and Error” why is sinusitis found to be predictive of a stroke? The data only represented people who had symptoms, went to the hospital, and got diagnosed with a stroke. Based on the data, the prediction was similar to prediction heavy utilization (propensity of people to seek cre) as well as the stroke. . | What is representation bias? When there is a clear imbalance, a model will find it and amplify it or maintain it. For example in occupations, models tend to predict females as nurses, and males as doctors. . | How are machines and people different, in terms of their use for making decisions? Machines can amplify bias with feedback loops very rapidly. Machines are implemented at scale without thinking of potential negative consequences, whereas people are usually screened more before being put into positions of power. . | Is disinformation the same as “fake news”? No, disinformation is making people not trust one another by intertwining real and fake news together. . | Why is disinformation through auto-generated text a particularly significant issue? Auto-generated disinformation scales a lot easier than human trolls. As a result, the amount of disinformation could exponentially increase without much resources. . | What are the five ethical lenses described by the Markkula Center? The Rights Approach: Which option best respects the rights of all who have a stake? The Justice Approach: Which option treats people equally or proportionately? The Utilitarian Approach: Which option will produce the most good and do the least harm? The Common Good Approach: Which option best serves the community as a whole, and not just some members? The Virtue Approach: Which option leads me to act as the sort of person I want to be? . | Where is policy an appropriate tool for addressing data ethics issues? If the data ethics issues are human rights issues, then the law is an appropriate tool. . |",
            "url": "https://datadote.github.io/blog/2020/04/06/fastbook_ch3_ans.html",
            "relUrl": "/2020/04/06/fastbook_ch3_ans.html",
            "date": " • Apr 6, 2020"
        }
        
    
  
    
        ,"post8": {
            "title": "Fastbook_ch2_ans",
            "content": "Chapter 2 answers to questions . Provide an example of where the bear classification model might work poorly, due to structural or style differences to the training data. Night time where the lighting is darker and images are more grayscale . | Where do text models currently have a major deficiency? Text models can mimic text well, but don’t seem to understand what they are mimicing. Text models are not good at generating correct responses . | What are possible negative societal implications of text generation models? Biases can be built into these models. These text models could be used for online trolling or spreading misinfromation on social media . | In situations where a model might make mistakes, and those mistakes could be harmful, what is a good alternative to automating a process? Add a human into the process to check the model’s predictions . | What kind of tabular data is deep learning particularly good at? Text, eg titles, reviews, comments . | What’s a key downside of directly using a deep learning model for recommendation systems? Deep learning models are predictors, not recommenders. So, the models look at your history, and find similar items. Rather than try to push your boundaries a little to see if you might like something new . | What are the steps of the Drivetrain approach? 1) Define objective 2) Figure out the levers 3) Get data 4) Use the data to model how the objective changes using the available levers . | How do the steps of the Drivetrain approach map to a recommendation system? The Drivetrain approach is a methodology to create actionable outcomes from data, and not just predictions. 1) Want more sales through recommendations 2) Rank the recommendations 3) Run experiments to see if new recommendations cause new sales 4) Compare new model with existing/baseline model to see if changes caused more sales from recommendations . | Create an image recognition model using data you curate, and deploy it on the web. Done . | What is DataLoaders? A dataloaders is a collection of dataloader objects from the FASTAI library A dataloader object contains information on how to retrieve the data (paths, names, labels, splits) . | What four things do we need to tell fastai to create DataLoaders? 1) What kind of data we are working with 2) How to get the list of items 3) How to label these images 4) How to create a validation set . | What does the splitter parameter to DataBlock do? Splitter tells the dataloaders function how to split the data into training and validation sets . | How do we ensure a random split always gives the same validation set? Pass a seed=### argument into the RandomSplitter. Use the same seed number each time . | What letters are often used to signify the independent and dependent variables? Independent = x Dependent = y . | What’s the difference between crop, pad, and squish resize approaches? When might you choose one over the other? Crop takes a centered crop of the image Pad adds 0’s to the perimeter of images if the images are too small (black borders) Squish squeezes an image into the specified size. Distorts image If the images are always centered, crop is ok. If you want the whole image without any changes, and have different sizes, then padding works. Use squish if you need faster compute, and the application actually has similar distortions. . | What is data augmentation? Why is it needed? Data augmentation is when you add transforms (change contrast, brightness, rotate, skew, flip, etc.) to images. Data augmentation is used when the training data is small, which seems to be the case for all image data sets. . | What is the difference between item_tfms and batch_tfms? Item_tfms does transformations on a per item basis, and is usually just used for resizing images. Item_tfms works before batch_tfms Batch_tfms applies transforms on a batch at a time. As a result, it assumes the inputs are all the same shape item_tfms and batch_tfms are arguments for the DataLoader class . | What is a confusion matrix? A confusion matrix is a table showing correct/wrong predictions, as well as false positives and false negatives. On the table, the y&gt;axis are the actual labels. On the x&gt;axis are the model predictions. Given a table x,y point, that point represents the number of times the actual label, and predicted label happened together. The diagonal of the table represents when the actual label and predicted label were the same. . | What does export save? Export saves a ‘.pkl’ file. This file contains the model architecture, parameters, and also the definition of how to create the dataloaders . | What is it called when we use a model for getting predictions, instead of training? Inference . | What are IPython widgets? Software that allows you to use JavaScript and Python in a web browser . | When might you want to use CPU for deployment? When might GPU be better? Use CPU for deployment when the user experience is adequate. CPU is generally cheaper. May want a GPU if you get enough traffic, and are able to batch together jobs . | What are the downsides of deploying your app to a server, instead of to a client (or edge) device such as a phone or PC? Deploying to your server means you have to maintain the hardware, and also the scaling burden is on you. On a phone, it is horizontal scaling and the client “takes” the scaling cost . | What are 3 examples of problems that could occur when rolling out a bear warning system in practice? 1) Out of domain data, 2) Domain shift Examples of “out of domain data” are low resolution photos, night time photos, latency between prediction and response to user . | What is “out of domain data”? Input data that has a distribution a lot different than the training data distribution . | What is “domain shift”? Domain shift is when your input data distribution changes, and moves away from the original training data distribution . | What are the 3 steps in the deployment process? 1) Manual process, run models in parallel and check outputs by hand 2) Limited scope deployment, try the model in the wild for a limited time/area and supervise the performance 3) Gradual expansion, expand the scope. This will require a good reporting system in order to get debugging information if things go wrong. For example, out of domain data or domain shift. . | For a project you’re interested in applying deep learning to, consider the thought experiment “what would happen if it went really, really well?” Done . | Start a blog, and write your first blog post. For instance, write about what you think deep learning might be useful for in a domain you’re interested in. Done. Thinking about an invasive flower classifier. . | Furthur research . Consider how the Drivetrain approach maps to a project or problem you’re interested in. I think the approach let’s you understand how different parts interact . | When might it be best to avoid certain types of data augmentation? When the data augmentation transforms images to look like another image label. For example, on MNIST, you do not want to do a horizontal flip because a b and d could look the same. Another example are numbers where you do not want to flip vertically because a 6 and a 9 could look the same . |",
            "url": "https://datadote.github.io/blog/2020/03/29/fastbook_ch2_ans.html",
            "relUrl": "/2020/03/29/fastbook_ch2_ans.html",
            "date": " • Mar 29, 2020"
        }
        
    
  
    
        ,"post9": {
            "title": "Fastbook_ch1_ans",
            "content": "Chapter 1 Answers to questions . 1) Do you need these for deep learning? Lots of math T / F Lots of data T / F Lots of expensive computers T / F A PhD T / F . FFFF . 2) Name five areas where deep learning is now the best in the world. . Vision, NLP, robotics, image generation, playing games, recommendation systems . 3) What was the name of the first device that was based on the principle of the artificial neuron? . The Mark I Perceptron . 4) Based on the book of the same name, what are the requirements for “Parallel Distributed Processing”? . Needs the following: set of processing units, a state of activation, an output function for each unit, a pattern of connectivity among units, a propagation rule for propagating patterns of activity through the network of connectivities, an activation rule to combine inputs, a learning rule where patterns of connectivity are modified by experience, an environment within which the system must operate . ?? 5) What were the two theoretical misunderstandings that held back the field of neural networks? . Marvin Minsky showing 1 layer of NN couldn’t perform some math functions (eg XOR) . 6) What is a GPU? . Graphics processing unit, good for matrix multiplication . 7) Open a notebook and execute a cell containing: 1+1. What happens? . Prints out 2 . 8) Follow through each cell of the stripped version of the notebook for this chapter. Before executing each cell, guess what will happen . Done . 9) Complete the Jupyter Notebook online appendix. . Done . 10) Why is it hard to use a traditional computer program to recognize images in a photo? . You have to write out rules explicitly. To recognize images would take an unreasonable amount of rules. . 11) What did Samuel mean by “Weight Assignment”? . Each processing unit has a weight associated with it. This weight is updated through training. . 12) What term do we normally use in deep learning for what Samuel called “Weights”? . model parameters . 13) Draw a picture that summarizes Arthur Samuel’s view of a machine learning model . Done . 14) Why is it hard to understand why a deep learning model makes a particular prediction? . Model learns from data, and does not explain the rules explicitly . 15) What is the name of the theorem that a neural network can solve any mathematical problem to any level of accuracy? . Universal Approximation Theorm . 16) What do you need in order to train a model? . Data . 17) How could a feedback loop impact the rollout of a predictive policing model? . Positive feedback increasing a bias. Examples include predictive models for arrests or collaborative filtering for youtube videos. . 18) Do we always have to use 224x224 pixel images with the cat recognition model? . Historical reasons on imagenet . 19) What is the difference between classification and regression? . Classification has discrete outputs. Linear regression has continuous outputs . 20) What is a validation set? What is a test set? Why do we need them? . Validation set is a portion of the dataset set aside for the human to evaluate performance. It is not used for training, but for evaluation of the training . 21) What will fastai do if you don’t provide a validation set? . Fastai will automatically make a validation set based off 20% of your training data . 22) Can we always use a random sample for a validation set? Why or why not? . No, because there is a chance the validation set does not represent the actual use case. An example is time series forecasting, we want to predict the future given the past. If our training data contains data in the future of the validation set, then there is data leakage. . 23) What is overfitting? Provide an example. . Overfitting is when the model memorizes pictures, and does not learn general features. An indicator of overfitting is when there is a large difference between the training and validation loss. An example might be a car dataset where the model sees a lot of Toyota cars, but can’t tell Honda cars are cars as well. Maybe the model learned to associate cars with the Toyota logo. . 24) What is a metric? How does it differ to “loss”? . A metric is a performance indicator for humans to understand. A loss is a performance indicator for models to use in order to train, and adjust weights. . 25) How can pretrained models help? . Pretrained models help by leveraging knowledge learned on other tasks. An example is image classification. Models trained on ImageNet learn low level features such as edges, textures, gradients, and can transfer this learned knowledge. Small datasets might not have enough data to let untrained models learn these low level features. . 26) What is the “head” of a model? . The head of a model is a smaller neural network added to the last layer of a pretrained model. This head is trainable, and fine-tuned to the applicable dataset. . 27) What kinds of features do the early layers of a CNN find? How about the later layers? . Early layers of a CNN learn low level features such as edges, lines, textures, gradients. Later layers combine the low level features, and contain more complex features such as shapes, text, faces. . 28) Are image models only useful for photos? . No, image models can used for other types of data as well. The caveat is the other types of data must be converted into images at some point. One example is speech. Speech spectrograms can be turned into pictures, and then fed into a model. . 29) What is an “architecture”? . An architecture is the skeleton of a neural network. This architecture includes the number of layers, number of weights, pattern of connections, and activation functions. . 30) What is segmentation? . Segmentation is the act of semantically classifying every pixel of an image. . 31) What is y_range used for? When do we need it? . y_range is used to indicate continuous variables for tabular data. . 32) What are “hyperparameters”? . Hyperparameters are parameters set by the human, and not learned by the model training. Examples of hyperparameters are the learning rate, activation functions, number of layers, number of weights to use. An example of not a parameter, but not a hyperparameter, are the weights of the neural network neurons. These weights are learned through training. . 33) What’s the best way to avoid failures when using AI in an organization? . Best way to avoid failures is to understand the importance of validation and test sets. Validation sets are used to verify the training performance. If the validation sets are used too often, there is a chance to overfit to the validation set. As a result, a test set is used to “double check” a model’s performance. A test set should be used seldomly to avoid overfitting to the test set. .",
            "url": "https://datadote.github.io/blog/2020/03/25/fastbook_ch1_ans.html",
            "relUrl": "/2020/03/25/fastbook_ch1_ans.html",
            "date": " • Mar 25, 2020"
        }
        
    
  
    
        ,"post10": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # Title &gt; Awesome summary - toc:true- branch: master- badges: true- comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . #collapse-hide import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . #collapse-show cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # single-value selection over [Major_Genre, MPAA_Rating] pairs # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(movies).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(movies).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=alt.Y(&#39;IMDB_Rating:Q&#39;, axis=alt.Axis(minExtent=30)), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=600, height=400 ) . Example 3: More Tooltips . # select a point for which to provide details-on-demand label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=700, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; df = pd.read_json(movies) # display table with pandas df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://datadote.github.io/blog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post11": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://datadote.github.io/blog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Circuit designer developing deep learning applications. Living in San Francisco bay area. Currently interested in computer vision. Tools: PyTorch, Tensorflow. .",
          "url": "https://datadote.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

}